{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Öykü Deniz Köse\n",
    "\n",
    "I hereby declare that I observed the honour code of the university when preparing the homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr?gr?mm?ng?H?m?w?rk\n",
    "\n",
    "In this exercise we model a string of text using a Markov(1) model. For simplicity we only consider letters 'a-z'. Capital letters 'A-Z' are mapped to the corresponding ones. All remaining letters, symbols, numbers, including spaces, are denoted by '.'.\n",
    "\n",
    "\n",
    "We have a probability table $T$ where $T_{i,j} = p(x_t = j | x_{t-1} = i)$  transition model of letters in English text for $t=1,2 \\dots N$. Assume that the initial letter in a string is always a space denoted as $x_0 = \\text{'.'}$. Such a model where the probability table is always the same is sometimes called a stationary model.\n",
    "\n",
    "1. For a given $N$, write a program to sample random strings with letters $x_1, x_2, \\dots, x_N$ from $p(x_{1:N}|x_0)$\n",
    "1. Now suppose you are given strings with missing letters, where each missing letter is denoted by a question mark (or underscore, as below). Implement a method, that samples missing letters conditioned on observed ones, i.e., samples from $p(x_{-\\alpha}|x_{\\alpha})$ where $\\alpha$ denotes indices of observed letters. For example, if the input is 't??.', we have $N=4$ and\n",
    "$x_1 = \\text{'t'}$ and $x_4 = \\text{'.'}$, $\\alpha=\\{1,4\\}$ and $-\\alpha=\\{2,3\\}$. Your program may possibly generate the strings 'the.', 'twi.', 'tee.', etc. Hint: make sure to make use all data given and sample from the correct distribution. Implement the method and print the results for the test strings below. \n",
    "1. Describe a method for filling in the gaps by estimating the most likely letter for each position. Hint: you need to compute\n",
    "$$\n",
    "x_{-\\alpha}^* = \\arg\\max_{x_{-\\alpha}} p(x_{-\\alpha}|x_{\\alpha})\n",
    "$$\n",
    "Implement the method and print the results for the following test strings along with the log-probability  $\\log p(x_{-\\alpha}^*,x_{\\alpha})$.\n",
    "1. Discuss how you can improve the model to get better estimations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_strings = ['th__br__n.f_x.', '_u_st__n_.to_be._nsw_r__','i__at_._a_h_n_._e_r_i_g','q___t.___z._____t.__.___.__.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: The code below loads a table of transition probabilities for English text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$p(x_t = \\text{'u'} | x_{t-1} = \\text{'q'})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9949749\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$p(x_t | x_{t-1} = \\text{'a'})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 0.0002835\n",
      "b 0.0228302\n",
      "c 0.0369041\n",
      "d 0.0426290\n",
      "e 0.0012216\n",
      "f 0.0075739\n",
      "g 0.0171385\n",
      "h 0.0014659\n",
      "i 0.0372661\n",
      "j 0.0002353\n",
      "k 0.0110124\n",
      "l 0.0778259\n",
      "m 0.0260757\n",
      "n 0.2145354\n",
      "o 0.0005459\n",
      "p 0.0195213\n",
      "q 0.0001749\n",
      "r 0.1104770\n",
      "s 0.0934290\n",
      "t 0.1317960\n",
      "u 0.0098029\n",
      "v 0.0306574\n",
      "w 0.0088799\n",
      "x 0.0009562\n",
      "y 0.0233701\n",
      "z 0.0018701\n",
      ". 0.0715219\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from IPython.display import display, Latex\n",
    "\n",
    "alphabet = [chr(i+ord('a')) for i in range(26)]\n",
    "alphabet.append('.')\n",
    "letter2idx = {c:i for i,c in enumerate(alphabet)}\n",
    "\n",
    "T = []\n",
    "with open('transitions.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        T.append(row)\n",
    "\n",
    "print('Example')\n",
    "## p(x_t = 'u' | x_{t-1} = 'q')\n",
    "display(Latex(r\"$p(x_t = \\text{'u'} | x_{t-1} = \\text{'q'})$\"))\n",
    "print(T[letter2idx['q']][letter2idx['u']])\n",
    "display(Latex(r\"$p(x_t | x_{t-1} = \\text{'a'})$\"))\n",
    "for c,p in zip(alphabet,T[letter2idx['a']]):\n",
    "    print(c,p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".wace..veas\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "#Part 1)\n",
    "\n",
    "N=10 #Specify the length of the random string\n",
    "choice='.'\n",
    "random_string=\"\"\n",
    "random_string=random_string+choice\n",
    "for j in range(N):\n",
    "    cdf={}\n",
    "    for i in range(len(alphabet)):\n",
    "        cdf[alphabet[i]]=Decimal(str(T[letter2idx[choice]][letter2idx[alphabet[i]]]))\n",
    "    pr= random.random()\n",
    "    Fx = 0\n",
    "    for c, p in cdf.items():\n",
    "        Fx = Fx + p\n",
    "        if (pr <= Fx):\n",
    "            choice = c\n",
    "            random_string=random_string+c\n",
    "            break\n",
    "            \n",
    "print(random_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the 1th missing letter/letters the maximizing letter series has the log probability-4.933091002188418\n",
      "For the 2th missing letter/letters the maximizing letter series has the log probability-5.275963684161198\n",
      "For the 3th missing letter/letters the maximizing letter series has the log probability-6.93208128464704\n",
      "the.brean.fex.\n",
      "For the 1th missing letter/letters the maximizing letter series has the log probability-3.300874634276711\n",
      "For the 2th missing letter/letters the maximizing letter series has the log probability-4.896730029412735\n",
      "For the 3th missing letter/letters the maximizing letter series has the log probability-4.376744460254719\n",
      "For the 4th missing letter/letters the maximizing letter series has the log probability-2.21088999523798\n",
      "For the 5th missing letter/letters the maximizing letter series has the log probability-5.182512738347487\n",
      "For the 6th missing letter/letters the maximizing letter series has the log probability-3.7813002863190257\n",
      "For the 7th missing letter/letters the maximizing letter series has the log probability-3.8635278011322436\n",
      "For the 8th missing letter/letters the maximizing letter series has the log probability-2.4926053258954557\n",
      "qursthend.to.be.answere.\n",
      "For the 1th missing letter/letters the maximizing letter series has the log probability-4.940454877077206\n",
      "For the 2th missing letter/letters the maximizing letter series has the log probability-3.267886254033386\n",
      "For the 3th missing letter/letters the maximizing letter series has the log probability-4.499707930142474\n",
      "For the 4th missing letter/letters the maximizing letter series has the log probability-3.1192511054359224\n",
      "For the 5th missing letter/letters the maximizing letter series has the log probability-3.2839933612067247\n",
      "For the 6th missing letter/letters the maximizing letter series has the log probability-2.21088999523798\n",
      "For the 7th missing letter/letters the maximizing letter series has the log probability-3.580556393696395\n",
      "For the 8th missing letter/letters the maximizing letter series has the log probability-4.886578272474838\n",
      "For the 9th missing letter/letters the maximizing letter series has the log probability-4.185613148654031\n",
      "For the 10th missing letter/letters the maximizing letter series has the log probability-3.469524304129173\n",
      "in.ath.wathend.he.r.ing\n",
      "For the 1th missing letter/letters the maximizing letter series has the log probability-4.955390630104563\n",
      "For the 2th missing letter/letters the maximizing letter series has the log probability-10.800982874622477\n",
      "For the 3th missing letter/letters the maximizing letter series has the log probability-8.667798401065937\n",
      "For the 4th missing letter/letters the maximizing letter series has the log probability-4.623088015752181\n",
      "For the 5th missing letter/letters the maximizing letter series has the log probability-4.836070152433443\n",
      "For the 6th missing letter/letters the maximizing letter series has the log probability-4.623088015752181\n",
      "qus.t.terz.teed.t.te.tee.te.\n"
     ]
    }
   ],
   "source": [
    "#Part 3) I implemented Viterbi algorithm to find the most likely sequence\n",
    "\n",
    "def find_subseq(previous,later,size):\n",
    "    pron=np.multiply(np.ones((int(len(alphabet)),int(size))),-5)\n",
    "    if(previous=='!'):\n",
    "        for i in range(int(len(alphabet))):\n",
    "            pron[i,0]=np.log(1/len(alphabet))\n",
    "            \n",
    "    else:\n",
    "        for i in range(int(len(alphabet))):\n",
    "            if(float(T[letter2idx[previous]][letter2idx[alphabet[i]]])==float(0)):\n",
    "                pron[i,0]=-10\n",
    "            else:\n",
    "                pron[i,0]=np.log(float(T[letter2idx[previous]][letter2idx[alphabet[i]]]))\n",
    "               \n",
    "    ind=np.multiply(np.ones(size),-1)\n",
    "    for i in range(1,int(size)):\n",
    "        for k in range(int(len(alphabet))):\n",
    "            if(float(T[letter2idx[alphabet[0]]][letter2idx[alphabet[k]]])==float(0)):\n",
    "                pron[k,i]=-10\n",
    "            else:\n",
    "                pron[k,i]=pron[0,i-1]+np.log(float(T[letter2idx[alphabet[0]]][letter2idx[alphabet[k]]]))\n",
    "               \n",
    "            ind[i-1]=0\n",
    "            for j in range(1,int(len(alphabet))):\n",
    "                if(float(T[letter2idx[alphabet[j]]][letter2idx[alphabet[k]]])==float(0)):\n",
    "                    pron[k,i]=pron[k,i]\n",
    "                elif(pron[j,i-1]+np.log(float(T[letter2idx[alphabet[j]]][letter2idx[alphabet[k]]]))>pron[k,i]):\n",
    "                    \n",
    "                    pron[k,i]=pron[j,i-1]+np.log(float(T[letter2idx[alphabet[j]]][letter2idx[alphabet[k]]]))\n",
    "                    ind[i-1]=j\n",
    "    if(later=='!'):\n",
    "        ind[size-1]=np.argmax(pron[:,size-1])\n",
    "        log_prob=max(pron[:,size-1])\n",
    "    else:\n",
    "        ind[size-1]=0\n",
    "        if(float(T[letter2idx[alphabet[0]]][letter2idx[later]])==float(0)):\n",
    "            prob=-100\n",
    "        else:\n",
    "            prob=pron[0,size-1]+np.log(float(T[letter2idx[alphabet[0]]][letter2idx[later]]))\n",
    "        log_prob=prob\n",
    "        for k in range(1,int(len(alphabet))):\n",
    "            if(float(T[letter2idx[alphabet[k]]][letter2idx[later]])==float(0)):\n",
    "                prob=prob\n",
    "            elif(pron[k,size-1]+np.log(float(T[letter2idx[alphabet[k]]][letter2idx[later]]))>prob):\n",
    "                prob=pron[k,size-1]+np.log(float(T[letter2idx[alphabet[k]]][letter2idx[later]]))\n",
    "                ind[size-1]=k\n",
    "                log_prob=prob\n",
    "            \n",
    "    return ind,log_prob\n",
    "                \n",
    "def prepare_test(test):\n",
    "    un=0\n",
    "    test_dict={}\n",
    "    for i in range(len(test)):\n",
    "        if(test[i]=='_' and i==0):\n",
    "            test_dict['init'+str(un)]='!'\n",
    "            test_dict['ind'+str(un)]=0\n",
    "            un=un+1\n",
    "            test_dict['len'+str(un-1)]=1\n",
    "        elif(test[i]=='_' and test[i-1]!='_'):\n",
    "            test_dict['init'+str(un)]=test[i-1]\n",
    "            test_dict['len'+str(un)]=1\n",
    "            test_dict['ind'+str(un)]=i\n",
    "            un=un+1\n",
    "        elif(test[i]=='_' and test[i-1]=='_'):\n",
    "            test_dict['len'+str(un-1)]=test_dict['len'+str(un-1)]+1\n",
    "        if(test[i]=='_' and i==len(test)-1):\n",
    "            test_dict['fin'+str(un-1)]='!'\n",
    "        elif(test[i]=='_' and test[i+1]!='_' and i!=len(test)-1):\n",
    "            test_dict['fin'+str(un-1)]=test[i+1]\n",
    "    test_m=\"\"\n",
    "    \n",
    "    for i in range(un):\n",
    "        ind,log_prob=find_subseq(test_dict['init'+str(i)],test_dict['fin'+str(i)],test_dict['len'+str(i)])\n",
    "        print(\"For the \"+str(i+1)+\"th missing letter/letters the maximizing letter series has the log probability\"+str(log_prob))\n",
    "        if(i==0):\n",
    "            test_m=test_m+test[0:test_dict['ind'+str(i)]]\n",
    "        else:\n",
    "            test_m=test_m+test[len(test_m):test_dict['ind'+str(i)]]\n",
    "        for j in range(len(ind)):\n",
    "            test_m=test_m+alphabet[int(ind[j])]\n",
    "    test_m=test_m+test[len(test_m):]\n",
    "            \n",
    "            \n",
    "        \n",
    "    return test_m\n",
    "    \n",
    "        \n",
    "for i in range(len(test_strings)):\n",
    "    print(prepare_test(test_strings[i]))        \n",
    "        \n",
    "        \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    " \n",
    "    \n",
    "\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4)\n",
    "\n",
    "# The order of the Markov model can be increased so that better results can be achieved with increasing computational cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
